---
layout: page
title: Research
permalink: /research/
---
<font size="+2"><strong> Working Papers</strong></font><br>
<strong><a href="https://zhongsongfa.weebly.com/uploads/4/8/4/4/48443905/23_the_consistency_of_rationality_measures.pdf"> The Consistency of Rationality Measures</a></strong><br>with Mingshi Chen, Tracy Xiao Liu, Songfa Zhong, and Yanju Zhou;
<p style="text-align:justify"><b><i>Abstract: </i></b>While rationality has been commonly assumed and measured in various settings, an unexplored question arises regarding the extent to which individuals with high rationality scores in one setting would exhibit high scores in another setting. This study investigates the consistency of rationality measures using revealed preference techniques. We combine budgetary decisions in the lab and food decisions in the field based on scanner data to measure the rationality of individual consumers in a large grocery store. We show that the rationality score for risky or social decisions in the lab is uncorrelated with that of food decisions in the field. By contrast, the rationality score is highly correlated between risky and social decisions in the lab, as well as between food decisions in the lab and in the field. We further show that behavioral factors including purchasing experience, personality traits and cognitive skills may underlie rationality scores across different environments.</p><br>
<strong><a href="https://arxiv.org/pdf/2305.12763.pdf"> The Emergence Rationality of GPT</a></strong><br>with Yiting Chen, Tracy Xiao Liu and Songfa Zhong;<br>Condianally Accepted at <u><i>Proceedings of the National Academy of Sciences</i></u><br>
<p style="text-align:justify"><b><i>Abstract: </i></b>As large language models (LLMs) like GPT become increasingly prevalent, it is essential that we assess their capabilities beyond language processing. This paper examines the economic rationality of GPT by instructing it to make budgetary decisions in four domains: risk, time, social, and food preferences. We measure economic rationality by assessing the consistency of GPT's decisions with utility maximization in classic revealed preference theory. We find that GPT's decisions are largely rational in each domain and demonstrate higher rationality score than those of human subjects in a parallel experiment and in the literature. Moreover, the estimated preference parameters of GPT are slightly different from human subjects and exhibit a lower degree of heterogeneity. We also find that the rationality scores are robust to the degree of randomness and demographic settings such as age and gender, but are sensitive to contexts based on the language frames of the choice situations. These results suggest the potential of LLMs to make good decisions and the need to further understand their capabilities, limitations, and underlying mechanisms.</p><br>
<strong>显示偏好理论：理性度量</strong><br>合作者：刘潇;


<font size="+2"><strong>Papers in Progress</strong></font><br>
<strong>Strategic, Individual Rationality on Work Performance</a></strong><br>with Tracy Xiao Liu, Shu Wang;
